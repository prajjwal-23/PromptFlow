"""add_enhanced_run_models

Revision ID: 6e23308072bc
Revises: ec338a026a64
Create Date: 2025-11-18 11:55:33.079156

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '6e23308072bc'
down_revision: Union[str, None] = 'ec338a026a64'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('run_events', schema=None) as batch_op:
        batch_op.add_column(sa.Column('memory_usage_mb', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('cpu_usage_percent', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('error_type', sa.String(), nullable=True))
        batch_op.add_column(sa.Column('stack_trace', sa.Text(), nullable=True))
        batch_op.add_column(sa.Column('execution_context', sa.JSON(), nullable=True))
        batch_op.add_column(sa.Column('node_config', sa.JSON(), nullable=True))
        batch_op.add_column(sa.Column('resource_id', sa.String(), nullable=True))
        batch_op.add_column(sa.Column('resource_type', sa.String(), nullable=True))
        batch_op.create_index(batch_op.f('ix_run_events_event_type'), ['event_type'], unique=False)
        batch_op.create_index(batch_op.f('ix_run_events_level'), ['level'], unique=False)
        batch_op.create_index(batch_op.f('ix_run_events_node_id'), ['node_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_run_events_run_id'), ['run_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_run_events_timestamp'), ['timestamp'], unique=False)

    with op.batch_alter_table('runs', schema=None) as batch_op:
        batch_op.add_column(sa.Column('config', sa.JSON(), nullable=True))
        batch_op.add_column(sa.Column('priority', sa.String(), nullable=False))
        batch_op.add_column(sa.Column('timeout_seconds', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('max_retries', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('memory_limit_mb', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('max_parallel_nodes', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('total_nodes', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('completed_nodes', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('failed_nodes', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('skipped_nodes', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('peak_memory_usage', sa.Integer(), nullable=True))
        batch_op.add_column(sa.Column('total_tokens_used', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('total_execution_time', sa.Float(), nullable=False))
        batch_op.add_column(sa.Column('run_metadata', sa.JSON(), nullable=True))
        batch_op.add_column(sa.Column('tags', sa.JSON(), nullable=True))
        batch_op.add_column(sa.Column('parent_run_id', sa.String(), nullable=True))
        batch_op.create_foreign_key(None, 'runs', ['parent_run_id'], ['id'])

    with op.batch_alter_table('workspaces', schema=None) as batch_op:
        batch_op.alter_column('description',
               existing_type=sa.VARCHAR(),
               type_=sa.Text(),
               existing_nullable=True)

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('workspaces', schema=None) as batch_op:
        batch_op.alter_column('description',
               existing_type=sa.Text(),
               type_=sa.VARCHAR(),
               existing_nullable=True)

    with op.batch_alter_table('runs', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.drop_column('parent_run_id')
        batch_op.drop_column('tags')
        batch_op.drop_column('run_metadata')
        batch_op.drop_column('total_execution_time')
        batch_op.drop_column('total_tokens_used')
        batch_op.drop_column('peak_memory_usage')
        batch_op.drop_column('skipped_nodes')
        batch_op.drop_column('failed_nodes')
        batch_op.drop_column('completed_nodes')
        batch_op.drop_column('total_nodes')
        batch_op.drop_column('max_parallel_nodes')
        batch_op.drop_column('memory_limit_mb')
        batch_op.drop_column('max_retries')
        batch_op.drop_column('timeout_seconds')
        batch_op.drop_column('priority')
        batch_op.drop_column('config')

    with op.batch_alter_table('run_events', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_run_events_timestamp'))
        batch_op.drop_index(batch_op.f('ix_run_events_run_id'))
        batch_op.drop_index(batch_op.f('ix_run_events_node_id'))
        batch_op.drop_index(batch_op.f('ix_run_events_level'))
        batch_op.drop_index(batch_op.f('ix_run_events_event_type'))
        batch_op.drop_column('resource_type')
        batch_op.drop_column('resource_id')
        batch_op.drop_column('node_config')
        batch_op.drop_column('execution_context')
        batch_op.drop_column('stack_trace')
        batch_op.drop_column('error_type')
        batch_op.drop_column('cpu_usage_percent')
        batch_op.drop_column('memory_usage_mb')

    # ### end Alembic commands ###
